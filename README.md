# Framework Avanzado para Evaluaci√≥n de Pipelines RAG

Este repositorio presenta un framework integral para construir, comparar y evaluar sistem√°ticamente tres arquitecturas de **Retrieval-Augmented Generation (RAG)** de complejidad creciente. El objetivo es analizar c√≥mo las decisiones de dise√±o‚Äîdesde el *chunking* y los *embeddings* hasta el *re-ranking* y la *expansi√≥n de contexto*‚Äîimpactan el rendimiento de los Modelos de Lenguaje Grandes (LLMs) en tareas de respuesta a preguntas.

## üìÑ Paper de Investigaci√≥n

Este proyecto se complementa con un paper de investigaci√≥n que profundiza en el marco te√≥rico, la metodolog√≠a y el an√°lisis de resultados. Para una comprensi√≥n m√°s detallada, puedes consultar el documento completo.

**[Descargar el Paper en PDF](data/Documento_final_IA)**

---

## üöÄ Los Pipelines: Un Vistazo T√©cnico

Se implementaron y evaluaron tres pipelines, cada uno representando una evoluci√≥n en sofisticaci√≥n.

### 1. Pipeline RAG Simple (Baseline)

Este pipeline establece una l√≠nea base fundamental. Aunque no fue evaluado formalmente contra el dataset PeerQA, su c√≥digo sirve como un excelente punto de partida y demuestra un rendimiento √≥ptimo para tareas de extracci√≥n de informaci√≥n de documentos PDF individuales.

-   **Carga y Parseo**: Utiliza la librer√≠a `PyMuPDF (fitz)` para una extracci√≥n de texto directa y eficiente desde archivos PDF.
-   **Chunking**: Implementa una estrategia de divisi√≥n de texto de tama√±o fijo (`fixed-size chunking`) con solapamiento.
-   **Embeddings**: Emplea el modelo `sentence-transformers/all-MiniLM-L6-v2`, un modelo ligero y r√°pido, ideal para una baseline.
-   **B√∫squeda (Retrieval)**: Realiza una b√∫squeda sem√°ntica a trav√©s de una implementaci√≥n manual de **similitud de coseno** en NumPy.
-   **Generaci√≥n**: Es compatible con m√∫ltiples LLMs, incluyendo `llama3-70b-8192` (v√≠a Groq), `gemini-2.0-flash` y `qwen` (v√≠a OpenRouter).
-   **Notebook**: `src/simple_rag_evaluation.ipynb`

### 2. Pipeline RAG Intermedio (Evaluado como "Basic")

Este pipeline introduce t√©cnicas est√°ndar de la industria para mejorar la calidad de la recuperaci√≥n de informaci√≥n, sirviendo como el primer nivel en nuestra evaluaci√≥n formal.

-   **Carga y Parseo**: Usa la librer√≠a `unstructured` para un parseo m√°s robusto que preserva metadatos estructurales del documento.
-   **Chunking**: Adopta `RecursiveCharacterTextSplitter` de LangChain, una t√©cnica m√°s avanzada que divide el texto respetando la estructura sem√°ntica (p√°rrafos, frases).
-   **Embeddings**: Utiliza `sentence-transformers/all-mpnet-base-v2` a trav√©s de `HuggingFaceEmbeddings`, un modelo m√°s potente que el de la baseline.
-   **B√∫squeda (Retrieval)**: Implementa un **recuperador h√≠brido** (`EnsembleRetriever` de LangChain) que combina:
    -   **B√∫squeda Densa/Vectorial**: Utilizando `ChromaDB` como vector store.
    -   **B√∫squeda Lexical**: Utilizando `BM25Retriever` para capturar relevancia basada en palabras clave.
    - Los resultados de ambos se combinan con una ponderaci√≥n de 0.7 (vectorial) y 0.3 (lexical).
-   **Automatizaci√≥n**: Introduce la clase `RAGEvaluationGenerator` para automatizar la generaci√≥n de respuestas en lotes, gestionar APIs y preparar los datos para la evaluaci√≥n final.
-   **Notebook**: `src/intermedia_rag_evaluation.ipynb`

### 3. Pipeline RAG Avanzado

Este es el pipeline m√°s sofisticado, incorporando m√∫ltiples optimizaciones de vanguardia para maximizar la precisi√≥n y relevancia del contexto.

-   **Embeddings**: Emplea `BAAI/bge-m3`, un modelo de embeddings de alto rendimiento, dise√±ado para una comprensi√≥n sem√°ntica superior.
-   **Vector Store**: Utiliza `Qdrant` como base de datos vectorial, optimizada para b√∫squedas a gran escala.
-   **Estrategias de B√∫squeda Avanzadas**:
    -   **B√∫squeda H√≠brida Optimizada**: Combina la b√∫squeda densa de Qdrant con un √≠ndice `BM25Okapi` construido din√°micamente.
    -   **Re-ranking**: Los resultados iniciales son re-ordenados usando un **Cross-Encoder** (`cross-encoder/ms-marco-MiniLM-L-12-v2`) para refinar la relevancia de los chunks.
-   **Ingenier√≠a de Contexto y Consulta**:
    -   **Expansi√≥n de Contexto**: Enriquece los chunks recuperados a√±adiendo fragmentos de texto adyacentes para dar m√°s contexto al LLM.
    -   **Expansi√≥n de Consulta**: Genera variaciones de la pregunta original para mejorar la cobertura de la b√∫squeda.
-   **Automatizaci√≥n**: La l√≥gica est√° encapsulada en la clase `OptimizedRAGPipeline`, y la evaluaci√≥n es gestionada por `AdvancedRAGEvaluationGenerator`.
-   **Notebook**: `src/advanced_rag_evaluation.ipynb`

## üìä Framework de Evaluaci√≥n

La evaluaci√≥n de los pipelines **Intermedio** y **Avanzado** se realiz√≥ con un enfoque riguroso.

-   **Dataset**: Se utiliz√≥ el dataset **PeerQA** de Hugging Face, que contiene preguntas y respuestas basadas en art√≠culos de investigaci√≥n acad√©mica, proveyendo un benchmark realista y desafiante.
-   **M√©tricas (con `ragas`)**:
    -   `Faithfulness`: Fidelidad de la respuesta al contexto.
    -   `Answer Relevancy`: Relevancia de la respuesta a la pregunta.
    -   `Context Precision`: Precisi√≥n de los documentos recuperados.
    -   `Context Recall`: Cobertura de los documentos recuperados.
-   **Automatizaci√≥n**: Las clases `RAGEvaluationGenerator` y `AdvancedRAGEvaluationGenerator` son el coraz√≥n de la evaluaci√≥n. Toman el dataset `PeerQA`, iteran sobre las preguntas, consultan el pipeline RAG correspondiente, generan respuestas con diferentes LLMs (Gemini, Llama, Qwen), y guardan los resultados en archivos `.json` estructurados, listos para ser analizados por el notebook `evaluacion.ipynb`.

### Resultados

El rendimiento comparativo de los modelos se visualiza en el siguiente heatmap:

![Heatmap de Resultados](src/heatmap_rag_models.png)

#### Fidelidad y Relevancia

| Modelo           | üîç Faithfulness | üéØ Answer Relevancy |
|------------------|-----------------|---------------------|
| Llama Advanced   | 0.756           | 0.385               |
| Llama Basic      | 0.763           | 0.113               |
| Qwen Advanced    | 0.814           | 0.428               |
| Qwen Basic       | 0.789           | 0.209               |
| Gemini Advanced  | 0.863           | 0.370               |
| Gemini Basic     | 0.750           | 0.237               |

#### Precisi√≥n y Cobertura del Contexto

| Modelo           | üéØ Context Precision | üîÅ Context Recall |
|------------------|----------------------|-------------------|
| Llama Advanced   | 0.602                | 0.505             |
| Llama Basic      | 0.277                | 0.168             |
| Qwen Advanced    | 0.711                | 0.553             |
| Qwen Basic       | 0.289                | 0.157             |
| Gemini Advanced  | 0.688                | 0.611             |
| Gemini Basic     | 0.272                | 0.141             |

## üìÇ Estructura del Repositorio

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ 1-s2.0-S0378517324005799-main.pdf  (Documento de ejemplo para pruebas)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ simple_rag_evaluation.ipynb       (Pipeline Baseline)
‚îÇ   ‚îú‚îÄ‚îÄ intermedia_rag_evaluation.ipynb   (Pipeline Intermedio, evaluado como "Basic")
‚îÇ   ‚îú‚îÄ‚îÄ advanced_rag_evaluation.ipynb     (Pipeline Avanzado)
‚îÇ   ‚îú‚îÄ‚îÄ evaluacion.ipynb                  (An√°lisis de resultados y generaci√≥n de heatmap)
‚îÇ   ‚îú‚îÄ‚îÄ rag_evaluation_results.json       (Ejemplo de salida de la evaluaci√≥n intermedia)
‚îÇ   ‚îî‚îÄ‚îÄ advanced_rag_evaluation_results.json (Ejemplo de salida de la evaluaci√≥n avanzada)
‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îî‚îÄ‚îÄ Plantilla para variables de entorno (API Keys).
‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ Dependencias de Python.
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Gu√≠a de Instalaci√≥n y Ejecuci√≥n

Esta gu√≠a detalla los pasos para configurar el entorno completo, incluyendo las bases de datos vectoriales en Docker y la evaluaci√≥n con modelos locales.

### 1. Pre-requisitos

-   **Python**: Se recomienda encarecidamente usar **Python 3.10.6**, ya que el proyecto fue desarrollado y probado con esta versi√≥n. El uso de otras versiones podr√≠a causar conflictos con las dependencias.
-   **Docker**: Necesitar√°s Docker Desktop instalado y en ejecuci√≥n para gestionar las bases de datos vectoriales.
-   **Git**: Para clonar el repositorio.

### 2. Configuraci√≥n del Entorno

#### Paso 2.1: Clonar el Repositorio
```bash
git clone <URL-DEL-REPOSITORIO>
cd <NOMBRE-DEL-DIRECTORIO>
```

#### Paso 2.2: Entorno Virtual y Dependencias
```bash
# Crear el entorno virtual con la versi√≥n recomendada de Python
python3.10 -m venv nuevo_rag

# Activar el entorno
# En Windows:
.\nuevo_rag\Scripts\activate
# En macOS/Linux:
source nuevo_rag/bin/activate

# Instalar las dependencias
pip install -r requirements.txt
```

#### Paso 2.3: Variables de Entorno
Copia el archivo de ejemplo y a√±ade tus claves de API para los modelos evaluados.
```bash
cp .env.example .env
```
Edita el archivo `.env` con tus credenciales:
```ini
# .env
GOOGLE_API_KEY="tu-api-key-de-google"
GROQ_API_KEY="tu-api-key-de-groq"
QWEN_API_KEY="tu-api-key-de-qwen"
OPENAI_API_KEY="tu-api-key-de-openai" # Necesaria para algunas evaluaciones de Ragas
```

### 3. Bases de Datos Vectoriales con Docker

Los pipelines intermedio y avanzado utilizan ChromaDB y Qdrant, respectivamente. La forma m√°s sencilla de ejecutarlos es a trav√©s de Docker.

#### Paso 3.1: Iniciar Contenedor de ChromaDB (Pipeline Intermedio)
Abre una terminal y ejecuta el siguiente comando para iniciar ChromaDB:
```bash
docker run -d --name chroma-rag -p 8000:8000 -v chroma_rag_data:/chroma/chroma chromadb/chroma:latest
```
Esto iniciar√° un contenedor de ChromaDB que escuchar√° en el puerto `8000` y persistir√° los datos en un volumen llamado `chroma_rag_data`.

#### Paso 3.2: Iniciar Contenedor de Qdrant (Pipeline Avanzado)
Abre otra terminal y ejecuta este comando para iniciar Qdrant:
```bash
docker run -d --name qdrant-rag -p 6333:6333 -p 6334:6334 \
    -v $(pwd)/qdrant_storage:/qdrant/storage \
    qdrant/qdrant:latest
```
Esto iniciar√° un contenedor de Qdrant que escuchar√° en el puerto `6333` y guardar√° los datos en una carpeta local `qdrant_storage`.

### 4. Ejecuci√≥n de los Notebooks

Una vez que el entorno y los contenedores est√©n listos, puedes ejecutar las evaluaciones.

1.  **Inicia Jupyter Lab**:
    ```bash
    jupyter lab
    ```
2.  **Verifica las Rutas**:
    **¬°Importante!** Antes de ejecutar las celdas, aseg√∫rate de que las rutas a los archivos (como los PDFs en `data/` o los datasets generados en `resultados/`) sean correctas para tu sistema operativo. Es posible que necesites ajustar las rutas relativas o absolutas dentro de los notebooks.

3.  **Ejecuta los Notebooks en Orden**:
    -   **`simple_rag_evaluation.ipynb`**: Este notebook es autocontenido y no depende de Docker.
    -   **`intermedia_rag_evaluation.ipynb`**: Este notebook se conectar√° al contenedor de **ChromaDB**. La primera vez que lo ejecutes, crear√° y poblar√° la base de datos vectorial.
    -   **`advanced_rag_evaluation.ipynb`**: Se conectar√° al contenedor de **Qdrant**. Al igual que el anterior, la primera ejecuci√≥n se encargar√° de la indexaci√≥n.

### 5. Evaluaci√≥n con Modelos Locales (Ollama)

El notebook `evaluation_via_local.ipynb` permite evaluar usando un modelo local a trav√©s de Ollama.

#### Paso 5.1: Instalar y Configurar Ollama
-   Descarga e instala Ollama desde su [sitio web oficial](https://ollama.com/).
-   Abre una terminal y descarga el modelo que se utiliza en el notebook (por ejemplo, `llama3`):
    ```bash
    ollama pull llama3
    ```
-   Una vez descargado, ejecuta el servidor de Ollama. Normalmente, se inicia autom√°ticamente despu√©s de la instalaci√≥n, pero puedes verificarlo con:
    ```bash
    ollama serve
    ```
    Esto dejar√° el servidor corriendo en segundo plano.

#### Paso 5.2: Ejecutar el Notebook de Evaluaci√≥n Local
-   Abre `evaluation_via_local.ipynb`.
-   **Verifica el nombre del modelo**: Aseg√∫rate de que el nombre del modelo instanciado en el notebook coincida exactamente con el que descargaste con Ollama (p. ej., `llama3`). Si usaste un modelo diferente, como `mistral`, cambia el nombre en el c√≥digo.
-   Ejecuta las celdas para realizar la evaluaci√≥n utilizando el modelo local.


## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un **issue** para discutir cambios o env√≠a un **pull request**.

## üìÑ Licencia

Este proyecto fue realizado para la asignatura de Inteligencia Artificial por el estudiante Daniel C. Blanco. Se permite su uso y distribuci√≥n no comercial.
