{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14575628",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = load_dataset(\"json\", data_files=\"gemini_ds.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93636eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from datasets import Dataset\n",
    "\n",
    "# ⚙️ Instancia el modelo Ollama\n",
    "ollama_llm = Ollama(model=\"llama3.1:8b\", timeout=60)  # Puedes usar otro como mistral, llama2, etc.\n",
    "\n",
    "# ⚙️ Wrappers\n",
    "llm = LangchainLLMWrapper(ollama_llm)\n",
    "\n",
    "embed_model = LangchainEmbeddingsWrapper(\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    ")\n",
    "\n",
    "# ⚙️ Asigna modelos a las métricas\n",
    "faithfulness.llm = llm\n",
    "faithfulness.embeddings = embed_model\n",
    "\n",
    "answer_relevancy.llm = llm\n",
    "answer_relevancy.embeddings = embed_model\n",
    "\n",
    "context_precision.llm = llm\n",
    "context_precision.embeddings = embed_model\n",
    "\n",
    "context_recall.llm = llm\n",
    "context_recall.embeddings = embed_model\n",
    "\n",
    "# # ⚠️ Usa batch_size pequeño\n",
    "\n",
    "\n",
    "# pri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51676c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(\n",
    "    eval_dataset,  # tu Dataset ya limpio con 'question', 'contexts', 'answer' y 'ground_truth'\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625787fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_dataset = load_dataset(\"json\", data_files=\"groq_ds.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ Usa batch_size pequeño\n",
    "results2 = evaluate(\n",
    "    groq_dataset,  # tu Dataset ya limpio con 'question', 'contexts', 'answer' y 'ground_truth'\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_ds = load_dataset(\"json\", data_files=\"qwen_ds.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f434da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = evaluate(\n",
    "    qwen_ds,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c4354",
   "metadata": {},
   "source": [
    "#### RESULTADOS PRIMERA COMBINACIÓN\n",
    "\n",
    "\n",
    "- chunk_size=512, chunk_overlap=150\n",
    "- temperatura de los modelos = 0.1\n",
    "- weights=[0.5, 0.5]  -> FIJOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dad43c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.5758, 'answer_relevancy': 0.4667, 'context_precision': 0.5831}\n",
      "{'faithfulness': 0.5005, 'answer_relevancy': 0.4123, 'context_precision': 0.4489}\n",
      "{'faithfulness': 0.5976, 'answer_relevancy': 0.3528, 'context_precision': 0.4911}\n"
     ]
    }
   ],
   "source": [
    "print(results3)\n",
    "print(results)\n",
    "print(results2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daef419",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.to_pandas()\n",
    "results_df.to_csv(\"gemini1.csv\", index=False)\n",
    "\n",
    "results2_df = results2.to_pandas()\n",
    "results2_df.to_csv(\"groq1.csv\", index=False)\n",
    "\n",
    "results3_df = results3.to_pandas()\n",
    "results3_df.to_csv(\"qwen1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19857caa",
   "metadata": {},
   "source": [
    "### PRUEBA SEGUNDA CONFIGURACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_ds_2 = load_dataset(\"json\", data_files=\"gemini_ds_2.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini2_results  = evaluate(\n",
    "    gemini_ds_2,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_ds2 = load_dataset(\"json\", data_files=\"groq_ds2.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq2_result  = evaluate(\n",
    "    groq_ds2,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e31fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_ds2 = load_dataset(\"json\", data_files=\"qwen_ds2.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9141ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen2_result  = evaluate(\n",
    "    qwen_ds2,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1696b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.6255, 'answer_relevancy': 0.2404, 'context_precision': 0.4920}\n",
      "{'faithfulness': 0.5923, 'answer_relevancy': 0.4211, 'context_precision': 0.4805}\n",
      "{'faithfulness': 0.5783, 'answer_relevancy': 0.4121, 'context_precision': 0.4941}\n"
     ]
    }
   ],
   "source": [
    "print(groq2_result)\n",
    "print(gemini2_results)\n",
    "print(qwen2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c20a6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini2_df = gemini2_results.to_pandas()\n",
    "gemini2_df.to_csv(\"gemini2.csv\", index=False)\n",
    "groq2_df = groq2_result.to_pandas()\n",
    "groq2_df.to_csv(\"groq2.csv\", index=False)\n",
    "qwen2_df = qwen2_result.to_pandas()\n",
    "qwen2_df.to_csv(\"qwen2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84725365",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_avanzado = load_dataset(\"json\", data_files=\"groq_advanced_ds.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_avanzado  = evaluate(\n",
    "    groq_avanzado,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_avanzado_ds = load_dataset(\"json\", data_files=\"gemini_advanced_ds.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_avanzado  = evaluate(\n",
    "    gemini_avanzado_ds,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_avanzado_ds = load_dataset(\"json\", data_files=\"qwen_advanced_ds.json\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_avanzado = evaluate(\n",
    "    qwen_avanzado_ds,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53999ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.6417, 'answer_relevancy': 0.5475, 'context_precision': 0.5904}\n",
      "{'faithfulness': 0.6557, 'answer_relevancy': 0.4179, 'context_precision': 0.6650}\n",
      "{'faithfulness': 0.7249, 'answer_relevancy': 0.5650, 'context_precision': 0.6690}\n"
     ]
    }
   ],
   "source": [
    "print(groq_avanzado)\n",
    "print(gemini_avanzado)\n",
    "print(qwen_avanzado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd804231",
   "metadata": {},
   "outputs": [],
   "source": [
    "geminiavanzado_df = gemini_avanzado.to_pandas()\n",
    "geminiavanzado_df.to_csv(\"gemini_avanzado.csv\", index=False)\n",
    "\n",
    "groqavanzado_df = groq_avanzado.to_pandas()\n",
    "groqavanzado_df.to_csv(\"groq_avanzado.csv\", index=False)\n",
    "\n",
    "qwenavanzado_df = qwen_avanzado.to_pandas()\n",
    "qwenavanzado_df.to_csv(\"qwen_avanzado.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6c317",
   "metadata": {},
   "source": [
    "#### Presentación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c44e3a",
   "metadata": {},
   "source": [
    "## Métricas RAGAS – Comparativa entre Configuraciones\n",
    "\n",
    "## Primera Arquitectura\n",
    "\n",
    "#### Configuración 1: `chunk_size=512`, `overlap=150`, `temp=0.1`\n",
    "\n",
    "| Modelo | Faithfulness  | Answer Relevancy  | Context Precision  |\n",
    "|--------|:--------------:|:------------------:|:-------------------:|\n",
    "| **Gemini 2.0 Flash** | 0.5758 | 0.4667 | 0.5831 |\n",
    "| **LLaMA 3.3 70B** | 0.5005 | 0.4123 | 0.4489 |\n",
    "| **Qwen 3 32B** | 0.5976 | 0.3528 | 0.4911 |\n",
    "\n",
    "#### Configuración 2: `chunk_size=800`, `overlap=250`, `temp=0.5`\n",
    "\n",
    "| Modelo | Faithfulness  | Answer Relevancy  | Context Precision  |\n",
    "|--------|:--------------:|:------------------:|:-------------------:|\n",
    "| **Gemini 2.0 Flash** | **0.6255** ⭐ | **0.2404** ⭐ | 0.4920 |\n",
    "| **LLaMA 3.3 70B** | **0.5923** ⭐ | 0.4211 | **0.4805** ⭐ |\n",
    "| **Qwen 3 32B** | 0.5783 | **0.4121** ⭐ | **0.4941** ⭐ |\n",
    "\n",
    "---\n",
    "\n",
    "### Mejores Rendimientos por Métrica:\n",
    "\n",
    "- **Faithfulness**: Gemini 2.0 Flash (Config 2) - 0.6255\n",
    "- **Answer Relevancy**: Gemini 2.0 Flash (Config 1) - 0.4667  \n",
    "- **Context Precision**: Qwen 3 32B (Config 2) - 0.4941"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630f042",
   "metadata": {},
   "source": [
    "## Métricas RAGAS – Segunda Arquitectura\n",
    "\n",
    "| Modelo | Faithfulness  | Answer Relevancy  | Context Precision  |\n",
    "|--------|:--------------:|:------------------:|:-------------------:|\n",
    "| **Gemini 2.0 Flash** | 0.6557 | 0.4179 | 0.6650 |\n",
    "| **LLaMA 3.3 70B (Groq)** | 0.6417 | 0.5475 | 0.5904 |\n",
    "| **Qwen 3 32B** | **0.7249** ⭐ | **0.5650** ⭐ | **0.6690** ⭐ |\n",
    "\n",
    "---\n",
    "\n",
    "### Mejores Rendimientos por Métrica:\n",
    "\n",
    "- **Faithfulness**: Qwen 3 32B - 0.7249\n",
    "- **Answer Relevancy**: Qwen 3 32B - 0.5650  \n",
    "- **Context Precision**: Qwen 3 32B - 0.6690\n",
    "\n",
    "Qwen 3 32B lidera en todas las métricas de evaluación"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
